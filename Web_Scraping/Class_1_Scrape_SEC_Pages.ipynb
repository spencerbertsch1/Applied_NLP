{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Class 1 Scrape SEC Pages.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChYHqRzKcvhw",
        "colab_type": "text"
      },
      "source": [
        "#Scrape SEC web pages for 10-Ks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5K-icOZ2dKjd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "import urllib.request\n",
        "import urllib\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ud28bQAQcqOE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_all_text_from_url(url_to_scrape):\n",
        "  page_html = urllib.request.urlopen(url_to_scrape)\n",
        "  page_parse =  BeautifulSoup(page_html, 'html.parser')\n",
        "  return page_parse.text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tX109weIczLm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sec_base_url= \"https://www.sec.gov/cgi-bin/browse-edgar?CIK=aapl&type=10-K&owner=exclude&action=getcompany&Find=Search\"\n",
        "sec_base_url_prefix = \"https://www.sec.gov/cgi-bin/browse-edgar?CIK=\"\n",
        "sec_base_url_suffix= \"&type=10-K&owner=exclude&action=getcompany&Find=Search\"\n",
        "SEC_main_url = \"https://www.sec.gov\"\n",
        "\n",
        "\n",
        "def get_SEC_base_url_from_stock_ticker(ticker):\n",
        "  sec_base_url = sec_base_url_prefix + ticker + sec_base_url_suffix\n",
        "  return sec_base_url\n",
        "\n",
        "\n",
        "def get_all_10k_text_from_ticker(stock_ticker):\n",
        "  list_of_10k_text = []\n",
        "  sec_base_url = get_SEC_base_url_from_stock_ticker(stock_ticker)\n",
        "  results_page = urllib.request.urlopen(sec_base_url)\n",
        "  SEC_page_parse = BeautifulSoup(results_page, 'html.parser')\n",
        "\n",
        "  # the third table is the one that contains the filed documents for various years\n",
        "  company_data_table = SEC_page_parse.findAll('table')[2]\n",
        "  for row in company_data_table.findAll('tr'):\n",
        "    for link in row.findAll('a', attrs={'href': re.compile(\"/Archives/edgar\")}):\n",
        "      link_text = link.get('href')\n",
        "      documents_page_url = SEC_main_url+link_text\n",
        "\n",
        "      doc_page_pre_parse = urllib.request.urlopen(documents_page_url)\n",
        "      doc_page_parse = BeautifulSoup(doc_page_pre_parse, 'html.parser')\n",
        "      doc_table = doc_page_parse.find('table', attrs={'summary' : \"Document Format Files\"})\n",
        "\n",
        "      # get the first hyperlink in the table\n",
        "      doc_link = doc_table.find('a')\n",
        "      doc_link_text = doc_link.get('href')\n",
        "      doc_link_text = SEC_main_url + doc_link_text\n",
        "\n",
        "      last_four_chaaracters_of_filename = doc_link_text[-4:]\n",
        "      if last_four_chaaracters_of_filename == \".txt\" or last_four_chaaracters_of_filename == \".htm\":\n",
        "        print('getting 10K text from',doc_link_text)\n",
        "\n",
        "        text_of_10k = get_all_text_from_url(doc_link_text)\n",
        "        list_of_10k_text.append(text_of_10k)\n",
        "  return list_of_10k_text\n",
        "\n",
        "stock_ticker = \"msft\"\n",
        "all_10k_text = get_all_10k_text_from_ticker(stock_ticker)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9FQ_OrIlm3r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S25NB4zilu7g",
        "colab_type": "text"
      },
      "source": [
        "# Creating a word cloud from a string\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQwnBk3slwpY",
        "colab_type": "text"
      },
      "source": [
        "Create a word cloud from the list of strings that represent all 10-Ks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEzyN0Ttl0HI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "allText = \"\"\n",
        "num = 0\n",
        "for one10K in all_10k_text:\n",
        "  allText += one10K + \" \"\n",
        "\n",
        "# generate word cloud from the string\n",
        "wordcloud = WordCloud().generate(allText)\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\") "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}