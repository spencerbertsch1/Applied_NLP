{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Class 1 Scrape web pages.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMq1gQE-c4hY",
        "colab_type": "text"
      },
      "source": [
        "#Scraping web pages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNIurq1P2K8D",
        "colab_type": "text"
      },
      "source": [
        "In this notebook we examine how to access the text that is in one or more web pages. Web pages are structured in the HTML format, which you can view from your web browser. Unfortunately web page authors can structure the information in their web pages in an arbitrary manner. To determine which HTML codes are associated with information of interest, we should examine the HTML code underlying a web page."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vy0fU33Ic7jb",
        "colab_type": "text"
      },
      "source": [
        "To see the HTML of a web page:<p>\n",
        "  \n",
        "\n",
        "*   **Google Chrome** - from the upper right menu (3 vertical dots) select  \"More Tools\"-\"Developer Tools\"\n",
        "*   **Microsoft Internet Explorer** - Press Ctrl+U or F12, then click the Debugger tab \n",
        "*  **Microsoft Edge** - Press Ctrl+U or F12 , then select the Elements tab \n",
        "* **Mozilla Firefox** - Press Ctrl+U\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgL0qLaFU7ON",
        "colab_type": "text"
      },
      "source": [
        "# Tuck Faculty Page"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcTbFUftU9cE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "faculty_url=\"https://www.tuck.dartmouth.edu/faculty/faculty-directory\"\n",
        "\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "import urllib.request\n",
        "import urllib\n",
        "import re\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6yq3TU6V13I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def convert_relative_link_to_full_url(link):\n",
        "  link_text = link.get('href')\n",
        "  link_text = link_text.replace(\"/faculty/faculty-directory\",\"\")\n",
        "  link_to_professor_page = faculty_url + link_text\n",
        "  return link_to_professor_page\n",
        "\n",
        "def get_professor_name(soup_of_professor_page):\n",
        "  title_items = soup_of_professor_page.find('div', attrs={'class': re.compile(\"row title fullWidth\")})\n",
        "  ZZZ = title_items.find('div', attrs={'class': \"large-6 medium-6 columns\"})\n",
        "  prof_name_element = ZZZ.find('h2')\n",
        "  prof_name = prof_name_element.text\n",
        "  return prof_name "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5fXom5rUJYi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The list professor_stats will contain a triplet for each professor. \n",
        "# The triplet for a professor contains the three strings:\n",
        "#     professor's name, the hyperlink to the professor's web page, and the text on the bio section of the professor's web page \n",
        "professor_stats = []\n",
        "\n",
        "results_page = urllib.request.urlopen(faculty_url)\n",
        "faculty_page_parse = BeautifulSoup(results_page, 'html.parser')\n",
        "\n",
        "# Iterate through all professor links that are on the faculty page\n",
        "# A link to a professor's web page is one which contains \"/faculty/faculty-directory/\"\n",
        "for relative_link in faculty_page_parse.findAll('a', attrs={'href': re.compile(\"/faculty/faculty-directory/\")}):\n",
        "  link_to_professor_page = convert_relative_link_to_full_url(relative_link)\n",
        "    \n",
        "  \n",
        "  professor_page_contents = urllib.request.urlopen(link_to_professor_page)\n",
        "  professor_page_parse = BeautifulSoup(professor_page_contents, 'html.parser')\n",
        "\n",
        "  professor_name = get_professor_name(professor_page_parse)\n",
        "  \n",
        "#   for bio_items in professor_page_parse.findAll('div', attrs={'class': re.compile(\"bio\")}):\n",
        "#     # get all text from the bio section\n",
        "#         bio_text = bio_items.text\n",
        "  \n",
        "  bio_items = professor_page_parse.find('div', attrs={'class': re.compile(\"bio\")})\n",
        "    # get all text from the bio section\n",
        "  bio_text = bio_items.text\n",
        "  \n",
        "  professor_triplet = (professor_name, link_to_professor_page, bio_text)\n",
        "  professor_stats.append(professor_triplet)\n",
        "  if len(professor_stats) % 10 == 0:\n",
        "    print('Found faculty pages for',len(professor_stats),'professors so far.')  \n",
        "\n",
        "\n",
        "  \n",
        "print('Found faculty pages for',len(professor_stats),'professors in total.') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4GRIW66sqL8",
        "colab_type": "text"
      },
      "source": [
        "# Make a word cloud from the text of all professor bios"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9rxsIbis7u3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "\n",
        "allText = \"\"\n",
        "num = 0\n",
        "for (_,_,bio_text) in professor_stats:\n",
        "#   bio_text = bio_text.translate( string.punctuation)\n",
        "  bio_text = re.sub(r'[^\\w\\s]','',bio_text)\n",
        "  allText += bio_text.lower()\n",
        "\n",
        "# generate word cloud from the string\n",
        "wc = WordCloud().generate(allText)\n",
        "plt.imshow(wc, interpolation='bilinear')\n",
        "plt.axis(\"off\") \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJK8GRi4xF9V",
        "colab_type": "text"
      },
      "source": [
        "Create a word frequency table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6AF-MP5xHqg",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "def get_word_frequencies_from_string(text):\n",
        "  word_frequencies = Counter()\n",
        "  tokens = text.split()\n",
        "  word_frequencies.update(tokens)\n",
        "\n",
        "  return word_frequencies\n",
        "\n",
        "print()\n",
        "word_frequencies =   get_word_frequencies_from_string(allText)\n",
        "  \n",
        "print(\"Most common words:\")\n",
        "print(\"Word\\tFrequency:\")\n",
        "for word, frequency in word_frequencies.most_common(20):\n",
        "  print(\"{}\\t{:,}\".format(word, frequency))\n",
        "  \n",
        "  \n",
        "print()\n",
        "print(\"Least common words:\")\n",
        "print(\"Word\\tFrequency:\")\n",
        "for word, frequency in word_frequencies.most_common()[:-11:-1] :\n",
        "  print(\"{}\\t{:,}\".format(word, frequency))  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZCPxE4jtzc9",
        "colab_type": "text"
      },
      "source": [
        "# Removing our own stop words from the bio text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y97H0UGgt4i-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate word cloud from the string using our own stopwords\n",
        "\n",
        "stop_words = STOPWORDS.union({ \"tuck\", \"school\", \"business\", \"professor\", \"academic\", \"university\", \"award\", \"awards\", \"research\",\"journal\", \"publications\"})\n",
        "\n",
        "wc = WordCloud(stopwords=stop_words).generate(allText)\n",
        "plt.imshow(wc, interpolation='bilinear')\n",
        "plt.axis(\"off\") "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8TVeKUe375o",
        "colab_type": "text"
      },
      "source": [
        "From the word frequency table, remove the stop words we defined above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhOn930g4A9v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for word in stop_words:\n",
        "    if word in word_frequencies:\n",
        "        del word_frequencies[word]\n",
        "\n",
        "        \n",
        "print(\"Most common words:\")\n",
        "print(\"Word\\tFrequency:\")\n",
        "for word, frequency in word_frequencies.most_common(20):\n",
        "  print(\"{}\\t{:,}\".format(word, frequency))\n",
        "  \n",
        "  \n",
        "print()\n",
        "print(\"Least common words:\")\n",
        "print(\"Word\\tFrequency:\")\n",
        "for word, frequency in word_frequencies.most_common()[:-11:-1] :\n",
        "  print(\"{}\\t{:,}\".format(word, frequency))  "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}